import streamlit as st
import pandas as pd
import sqlite3
import requests
import os

from utils import parse_date_thai  # ‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≤‡∏Å utils.py

@st.cache_data(ttl=900)
def load_sqlite_data():
    db_path = "health_data.sqlite"
    file_id = "1HruO9AMrUfniC8hBWtumVdxLJayEc1Xr"
    gdrive_url = f"https://drive.google.com/uc?export=download&id={file_id}"

    # ‚úÖ ‡∏ñ‡πâ‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ ‡πÉ‡∏´‡πâ‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å Google Drive
    if not os.path.exists(db_path):
        with st.spinner("üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Google Drive..."):
            with requests.get(gdrive_url, stream=True) as r:
                if r.status_code != 200:
                    st.error("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å Google Drive ‡πÑ‡∏î‡πâ")
                    return pd.DataFrame()
                with open(db_path, "wb") as f:
                    for chunk in r.iter_content(chunk_size=8192):
                        f.write(chunk)

    # ‚úÖ ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å SQLite
    conn = sqlite3.connect(db_path)
    df = pd.read_sql("SELECT * FROM health_data", conn)
    conn.close()

    # ‚úÖ ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à" ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô datetime (‡∏à‡∏≤‡∏Å utils)
    df["‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à"] = df["‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à"].apply(parse_date_thai)

    # ‚úÖ ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤ missing ‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢
    df = df.fillna("").replace("nan", "")
    return df
